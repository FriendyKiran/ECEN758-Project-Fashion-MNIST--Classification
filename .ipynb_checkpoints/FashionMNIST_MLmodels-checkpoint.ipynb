{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST Classification project - KNN, Logistic Regression, Decision Tree Classifier, Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    33.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5     0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "6     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7     0.0     0.0     0.0     0.0     0.0     1.0     1.0     0.0     0.0   \n",
       "8     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...     114.0     130.0      76.0       0.0       0.0       0.0   \n",
       "2     22.0  ...       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "3     96.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "5     22.0  ...       0.0       0.0       0.0     133.0     167.0      73.0   \n",
       "6      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "7      0.0  ...       0.0       3.0       0.0      82.0     237.0     231.0   \n",
       "8      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  target  \n",
       "0       0.0       0.0       0.0       9  \n",
       "1       0.0       0.0       0.0       0  \n",
       "2       0.0       0.0       0.0       0  \n",
       "3       0.0       0.0       0.0       3  \n",
       "4       0.0       0.0       0.0       0  \n",
       "5       0.0       0.0       0.0       2  \n",
       "6       0.0       0.0       0.0       7  \n",
       "7      70.0       0.0       0.0       2  \n",
       "8       0.0       0.0       0.0       5  \n",
       "9       0.0       0.0       0.0       5  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Fashion-Mnist Dataset\n",
    "fashion_mnist = fetch_openml(name=\"Fashion-MNIST\", cache = True)\n",
    "fashion_mnist_df = pd.DataFrame(fashion_mnist.data, columns=fashion_mnist.feature_names)\n",
    "fashion_mnist_df['target'] = fashion_mnist['target'].astype(int)\n",
    "fashion_mnist_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FashionMNIST dataset contains 70000 samples and with 784 pixel values and target column\n"
     ]
    }
   ],
   "source": [
    "print(f'The FashionMNIST dataset contains {fashion_mnist_df.shape[0]} samples and with {fashion_mnist_df.shape[1]-1} pixel values and target column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "           ..\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "target      0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking missing values in the dataset\n",
    "fashion_mnist_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.00000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.034486</td>\n",
       "      <td>0.098886</td>\n",
       "      <td>0.247843</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>2.204386</td>\n",
       "      <td>5.634900</td>\n",
       "      <td>14.41000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.288643</td>\n",
       "      <td>16.611600</td>\n",
       "      <td>17.823371</td>\n",
       "      <td>22.887986</td>\n",
       "      <td>17.968129</td>\n",
       "      <td>8.524043</td>\n",
       "      <td>2.75140</td>\n",
       "      <td>0.836529</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.087339</td>\n",
       "      <td>0.296605</td>\n",
       "      <td>1.200882</td>\n",
       "      <td>2.458872</td>\n",
       "      <td>4.408110</td>\n",
       "      <td>5.842288</td>\n",
       "      <td>8.186472</td>\n",
       "      <td>14.117208</td>\n",
       "      <td>23.698865</td>\n",
       "      <td>38.18827</td>\n",
       "      <td>...</td>\n",
       "      <td>48.935288</td>\n",
       "      <td>42.075046</td>\n",
       "      <td>43.901606</td>\n",
       "      <td>51.853192</td>\n",
       "      <td>45.231601</td>\n",
       "      <td>29.527900</td>\n",
       "      <td>17.38577</td>\n",
       "      <td>9.258426</td>\n",
       "      <td>2.129924</td>\n",
       "      <td>2.872302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pixel1        pixel2        pixel3        pixel4        pixel5  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.000771      0.006414      0.034486      0.098886      0.247843   \n",
       "std        0.087339      0.296605      1.200882      2.458872      4.408110   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       16.000000     45.000000    218.000000    185.000000    227.000000   \n",
       "\n",
       "             pixel6        pixel7        pixel8        pixel9      pixel10  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.00000   \n",
       "mean       0.408714      0.802900      2.204386      5.634900     14.41000   \n",
       "std        5.842288      8.186472     14.117208     23.698865     38.18827   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "max      230.000000    224.000000    225.000000    254.000000    255.00000   \n",
       "\n",
       "       ...      pixel776      pixel777      pixel778      pixel779  \\\n",
       "count  ...  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean   ...     23.288643     16.611600     17.823371     22.887986   \n",
       "std    ...     48.935288     42.075046     43.901606     51.853192   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      8.000000      0.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel780      pixel781     pixel782      pixel783      pixel784  \\\n",
       "count  70000.000000  70000.000000  70000.00000  70000.000000  70000.000000   \n",
       "mean      17.968129      8.524043      2.75140      0.836529      0.072914   \n",
       "std       45.231601     29.527900     17.38577      9.258426      2.129924   \n",
       "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.00000    255.000000    170.000000   \n",
       "\n",
       "             target  \n",
       "count  70000.000000  \n",
       "mean       4.500000  \n",
       "std        2.872302  \n",
       "min        0.000000  \n",
       "25%        2.000000  \n",
       "50%        4.500000  \n",
       "75%        7.000000  \n",
       "max        9.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "X = fashion_mnist_df.drop('target', axis = 1).values #Get the data 28x28 total 784 features\n",
    "y = fashion_mnist_df['target'].values #Get the target values or class\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "def true_label(x):\n",
    "    return class_mapping[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking some data samples\n",
    "plt.figure(figsize=(10, 5))\n",
    "k = [0, 1, 2, 34, 500, 14578, 50000, 69999]\n",
    "\n",
    "for i, example in enumerate(k, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    g = plt.imshow(X.reshape(-1, 28, 28, 1)[example][:, :, 0], cmap=plt.cm.binary)\n",
    "    plt.title('Class: ' + true_label(y[example]))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Dimentionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the scale of pixels from 0-1 \n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "\n",
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "pca = PCA(n_components = 0.95) \n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after Dimensionality Reduction:  (60000, 187)\n",
      "X_test shape after Dimensionality Reduction:  (10000, 187)\n",
      "The total variance captured after Dimensionality Reduction is:  0.9500039103537354\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape after Dimensionality Reduction: \",X_train_pca.shape)\n",
    "print(\"X_test shape after Dimensionality Reduction: \", X_test_pca.shape)\n",
    "print(\"The total variance captured after Dimensionality Reduction is: \", np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START metric=euclidean, n_neighbors=1.............................\n",
      "[CV 1/3; 1/8] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.848) total time=   2.3s\n",
      "[CV 2/3; 1/8] START metric=euclidean, n_neighbors=1.............................\n",
      "[CV 2/3; 1/8] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.851) total time=   2.0s\n",
      "[CV 3/3; 1/8] START metric=euclidean, n_neighbors=1.............................\n",
      "[CV 3/3; 1/8] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.848) total time=   2.1s\n",
      "[CV 1/3; 2/8] START metric=euclidean, n_neighbors=2.............................\n",
      "[CV 1/3; 2/8] END metric=euclidean, n_neighbors=2;, score=(train=0.931, test=0.844) total time=   2.2s\n",
      "[CV 2/3; 2/8] START metric=euclidean, n_neighbors=2.............................\n",
      "[CV 2/3; 2/8] END metric=euclidean, n_neighbors=2;, score=(train=0.929, test=0.847) total time=   2.1s\n",
      "[CV 3/3; 2/8] START metric=euclidean, n_neighbors=2.............................\n",
      "[CV 3/3; 2/8] END metric=euclidean, n_neighbors=2;, score=(train=0.930, test=0.847) total time=   2.1s\n",
      "[CV 1/3; 3/8] START metric=euclidean, n_neighbors=3.............................\n",
      "[CV 1/3; 3/8] END metric=euclidean, n_neighbors=3;, score=(train=0.920, test=0.855) total time=   2.1s\n",
      "[CV 2/3; 3/8] START metric=euclidean, n_neighbors=3.............................\n",
      "[CV 2/3; 3/8] END metric=euclidean, n_neighbors=3;, score=(train=0.921, test=0.857) total time=   2.2s\n",
      "[CV 3/3; 3/8] START metric=euclidean, n_neighbors=3.............................\n",
      "[CV 3/3; 3/8] END metric=euclidean, n_neighbors=3;, score=(train=0.921, test=0.857) total time=   2.2s\n",
      "[CV 1/3; 4/8] START metric=euclidean, n_neighbors=4.............................\n",
      "[CV 1/3; 4/8] END metric=euclidean, n_neighbors=4;, score=(train=0.910, test=0.861) total time=   2.1s\n",
      "[CV 2/3; 4/8] START metric=euclidean, n_neighbors=4.............................\n",
      "[CV 2/3; 4/8] END metric=euclidean, n_neighbors=4;, score=(train=0.909, test=0.862) total time=   2.2s\n",
      "[CV 3/3; 4/8] START metric=euclidean, n_neighbors=4.............................\n",
      "[CV 3/3; 4/8] END metric=euclidean, n_neighbors=4;, score=(train=0.910, test=0.859) total time=   2.2s\n",
      "[CV 1/3; 5/8] START metric=manhattan, n_neighbors=1.............................\n",
      "[CV 1/3; 5/8] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.852) total time=  15.8s\n",
      "[CV 2/3; 5/8] START metric=manhattan, n_neighbors=1.............................\n",
      "[CV 2/3; 5/8] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.854) total time=  16.6s\n",
      "[CV 3/3; 5/8] START metric=manhattan, n_neighbors=1.............................\n",
      "[CV 3/3; 5/8] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.853) total time=  17.9s\n",
      "[CV 1/3; 6/8] START metric=manhattan, n_neighbors=2.............................\n",
      "[CV 1/3; 6/8] END metric=manhattan, n_neighbors=2;, score=(train=0.933, test=0.845) total time=  17.0s\n",
      "[CV 2/3; 6/8] START metric=manhattan, n_neighbors=2.............................\n",
      "[CV 2/3; 6/8] END metric=manhattan, n_neighbors=2;, score=(train=0.931, test=0.853) total time=  16.6s\n",
      "[CV 3/3; 6/8] START metric=manhattan, n_neighbors=2.............................\n",
      "[CV 3/3; 6/8] END metric=manhattan, n_neighbors=2;, score=(train=0.931, test=0.850) total time= 1.0min\n",
      "[CV 1/3; 7/8] START metric=manhattan, n_neighbors=3.............................\n",
      "[CV 1/3; 7/8] END metric=manhattan, n_neighbors=3;, score=(train=0.923, test=0.857) total time=  15.3s\n",
      "[CV 2/3; 7/8] START metric=manhattan, n_neighbors=3.............................\n",
      "[CV 2/3; 7/8] END metric=manhattan, n_neighbors=3;, score=(train=0.922, test=0.862) total time=  15.1s\n",
      "[CV 3/3; 7/8] START metric=manhattan, n_neighbors=3.............................\n",
      "[CV 3/3; 7/8] END metric=manhattan, n_neighbors=3;, score=(train=0.922, test=0.856) total time=  16.1s\n",
      "[CV 1/3; 8/8] START metric=manhattan, n_neighbors=4.............................\n",
      "[CV 1/3; 8/8] END metric=manhattan, n_neighbors=4;, score=(train=0.913, test=0.861) total time=  16.9s\n",
      "[CV 2/3; 8/8] START metric=manhattan, n_neighbors=4.............................\n",
      "[CV 2/3; 8/8] END metric=manhattan, n_neighbors=4;, score=(train=0.912, test=0.865) total time=  16.8s\n",
      "[CV 3/3; 8/8] START metric=manhattan, n_neighbors=4.............................\n",
      "[CV 3/3; 8/8] END metric=manhattan, n_neighbors=4;, score=(train=0.912, test=0.859) total time=  17.2s\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 4}\n",
      "Test Accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "#defining parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 5),  # Try different values of k\n",
    "    'metric': ['euclidean', 'manhattan']  # Distance metrics\n",
    "}\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', return_train_score = True, verbose=10)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_knn.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save KNN model to a file\n",
    "with open('Best_Models/K_Nearest_Neighbors/knn.pkl', 'wb') as file:\n",
    "    pickle.dump(best_knn, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV 1/3; 1/14] START C=0.001, max_iter=50.......................................\n",
      "[CV 1/3; 1/14] END C=0.001, max_iter=50;, score=(train=0.815, test=0.814) total time=   1.7s\n",
      "[CV 2/3; 1/14] START C=0.001, max_iter=50.......................................\n",
      "[CV 2/3; 1/14] END C=0.001, max_iter=50;, score=(train=0.814, test=0.814) total time=   1.3s\n",
      "[CV 3/3; 1/14] START C=0.001, max_iter=50.......................................\n",
      "[CV 3/3; 1/14] END C=0.001, max_iter=50;, score=(train=0.815, test=0.812) total time=   1.5s\n",
      "[CV 1/3; 2/14] START C=0.001, max_iter=100......................................\n",
      "[CV 1/3; 2/14] END C=0.001, max_iter=100;, score=(train=0.815, test=0.814) total time=   3.0s\n",
      "[CV 2/3; 2/14] START C=0.001, max_iter=100......................................\n",
      "[CV 2/3; 2/14] END C=0.001, max_iter=100;, score=(train=0.814, test=0.814) total time=   2.7s\n",
      "[CV 3/3; 2/14] START C=0.001, max_iter=100......................................\n",
      "[CV 3/3; 2/14] END C=0.001, max_iter=100;, score=(train=0.815, test=0.812) total time=   2.8s\n",
      "[CV 1/3; 3/14] START C=0.01, max_iter=50........................................\n",
      "[CV 1/3; 3/14] END C=0.01, max_iter=50;, score=(train=0.852, test=0.845) total time=   1.2s\n",
      "[CV 2/3; 3/14] START C=0.01, max_iter=50........................................\n",
      "[CV 2/3; 3/14] END C=0.01, max_iter=50;, score=(train=0.850, test=0.851) total time=   1.3s\n",
      "[CV 3/3; 3/14] START C=0.01, max_iter=50........................................\n",
      "[CV 3/3; 3/14] END C=0.01, max_iter=50;, score=(train=0.851, test=0.846) total time=   1.4s\n",
      "[CV 1/3; 4/14] START C=0.01, max_iter=100.......................................\n",
      "[CV 1/3; 4/14] END C=0.01, max_iter=100;, score=(train=0.852, test=0.845) total time=   2.7s\n",
      "[CV 2/3; 4/14] START C=0.01, max_iter=100.......................................\n",
      "[CV 2/3; 4/14] END C=0.01, max_iter=100;, score=(train=0.850, test=0.851) total time=   2.5s\n",
      "[CV 3/3; 4/14] START C=0.01, max_iter=100.......................................\n",
      "[CV 3/3; 4/14] END C=0.01, max_iter=100;, score=(train=0.851, test=0.846) total time=   2.4s\n",
      "[CV 1/3; 5/14] START C=0.1, max_iter=50.........................................\n",
      "[CV 1/3; 5/14] END C=0.1, max_iter=50;, score=(train=0.861, test=0.851) total time=   1.3s\n",
      "[CV 2/3; 5/14] START C=0.1, max_iter=50.........................................\n",
      "[CV 2/3; 5/14] END C=0.1, max_iter=50;, score=(train=0.860, test=0.856) total time=   1.3s\n",
      "[CV 3/3; 5/14] START C=0.1, max_iter=50.........................................\n",
      "[CV 3/3; 5/14] END C=0.1, max_iter=50;, score=(train=0.860, test=0.853) total time=   1.3s\n",
      "[CV 1/3; 6/14] START C=0.1, max_iter=100........................................\n",
      "[CV 1/3; 6/14] END C=0.1, max_iter=100;, score=(train=0.865, test=0.852) total time=   2.4s\n",
      "[CV 2/3; 6/14] START C=0.1, max_iter=100........................................\n",
      "[CV 2/3; 6/14] END C=0.1, max_iter=100;, score=(train=0.863, test=0.858) total time=   3.0s\n",
      "[CV 3/3; 6/14] START C=0.1, max_iter=100........................................\n",
      "[CV 3/3; 6/14] END C=0.1, max_iter=100;, score=(train=0.863, test=0.856) total time=   3.1s\n",
      "[CV 1/3; 7/14] START C=1, max_iter=50...........................................\n",
      "[CV 1/3; 7/14] END C=1, max_iter=50;, score=(train=0.863, test=0.851) total time=   1.7s\n",
      "[CV 2/3; 7/14] START C=1, max_iter=50...........................................\n",
      "[CV 2/3; 7/14] END C=1, max_iter=50;, score=(train=0.860, test=0.856) total time=   1.8s\n",
      "[CV 3/3; 7/14] START C=1, max_iter=50...........................................\n",
      "[CV 3/3; 7/14] END C=1, max_iter=50;, score=(train=0.862, test=0.855) total time=   1.6s\n",
      "[CV 1/3; 8/14] START C=1, max_iter=100..........................................\n",
      "[CV 1/3; 8/14] END C=1, max_iter=100;, score=(train=0.867, test=0.851) total time=   3.1s\n",
      "[CV 2/3; 8/14] START C=1, max_iter=100..........................................\n",
      "[CV 2/3; 8/14] END C=1, max_iter=100;, score=(train=0.865, test=0.858) total time=   3.3s\n",
      "[CV 3/3; 8/14] START C=1, max_iter=100..........................................\n",
      "[CV 3/3; 8/14] END C=1, max_iter=100;, score=(train=0.865, test=0.856) total time=   2.7s\n",
      "[CV 1/3; 9/14] START C=10, max_iter=50..........................................\n",
      "[CV 1/3; 9/14] END C=10, max_iter=50;, score=(train=0.863, test=0.851) total time=   1.2s\n",
      "[CV 2/3; 9/14] START C=10, max_iter=50..........................................\n",
      "[CV 2/3; 9/14] END C=10, max_iter=50;, score=(train=0.860, test=0.856) total time=   1.2s\n",
      "[CV 3/3; 9/14] START C=10, max_iter=50..........................................\n",
      "[CV 3/3; 9/14] END C=10, max_iter=50;, score=(train=0.861, test=0.854) total time=   1.3s\n",
      "[CV 1/3; 10/14] START C=10, max_iter=100........................................\n",
      "[CV 1/3; 10/14] END C=10, max_iter=100;, score=(train=0.867, test=0.851) total time=   2.3s\n",
      "[CV 2/3; 10/14] START C=10, max_iter=100........................................\n",
      "[CV 2/3; 10/14] END C=10, max_iter=100;, score=(train=0.865, test=0.858) total time=   2.6s\n",
      "[CV 3/3; 10/14] START C=10, max_iter=100........................................\n",
      "[CV 3/3; 10/14] END C=10, max_iter=100;, score=(train=0.865, test=0.856) total time=   3.0s\n",
      "[CV 1/3; 11/14] START C=100, max_iter=50........................................\n",
      "[CV 1/3; 11/14] END C=100, max_iter=50;, score=(train=0.863, test=0.852) total time=   1.2s\n",
      "[CV 2/3; 11/14] START C=100, max_iter=50........................................\n",
      "[CV 2/3; 11/14] END C=100, max_iter=50;, score=(train=0.860, test=0.855) total time=   1.4s\n",
      "[CV 3/3; 11/14] START C=100, max_iter=50........................................\n",
      "[CV 3/3; 11/14] END C=100, max_iter=50;, score=(train=0.862, test=0.854) total time=   1.4s\n",
      "[CV 1/3; 12/14] START C=100, max_iter=100.......................................\n",
      "[CV 1/3; 12/14] END C=100, max_iter=100;, score=(train=0.867, test=0.851) total time=   2.4s\n",
      "[CV 2/3; 12/14] START C=100, max_iter=100.......................................\n",
      "[CV 2/3; 12/14] END C=100, max_iter=100;, score=(train=0.865, test=0.858) total time=   2.5s\n",
      "[CV 3/3; 12/14] START C=100, max_iter=100.......................................\n",
      "[CV 3/3; 12/14] END C=100, max_iter=100;, score=(train=0.866, test=0.857) total time=   2.4s\n",
      "[CV 1/3; 13/14] START C=1000, max_iter=50.......................................\n",
      "[CV 1/3; 13/14] END C=1000, max_iter=50;, score=(train=0.863, test=0.852) total time=   1.3s\n",
      "[CV 2/3; 13/14] START C=1000, max_iter=50.......................................\n",
      "[CV 2/3; 13/14] END C=1000, max_iter=50;, score=(train=0.860, test=0.855) total time=   1.3s\n",
      "[CV 3/3; 13/14] START C=1000, max_iter=50.......................................\n",
      "[CV 3/3; 13/14] END C=1000, max_iter=50;, score=(train=0.862, test=0.854) total time=   1.3s\n",
      "[CV 1/3; 14/14] START C=1000, max_iter=100......................................\n",
      "[CV 1/3; 14/14] END C=1000, max_iter=100;, score=(train=0.867, test=0.850) total time=   2.5s\n",
      "[CV 2/3; 14/14] START C=1000, max_iter=100......................................\n",
      "[CV 2/3; 14/14] END C=1000, max_iter=100;, score=(train=0.865, test=0.858) total time=   3.0s\n",
      "[CV 3/3; 14/14] START C=1000, max_iter=100......................................\n",
      "[CV 3/3; 14/14] END C=1000, max_iter=100;, score=(train=0.865, test=0.856) total time=   3.5s\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 100}\n",
      "Test Accuracy: 0.8422\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'max_iter': [50, 100]}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=3, scoring='accuracy', return_train_score = True, verbose=10)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_log_reg.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Logistic Regression model to a file\n",
    "with open('Best_Models/Logistic_Regression/LogReg.pkl', 'wb') as file:\n",
    "    pickle.dump(best_log_reg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 1/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.750) total time=  12.9s\n",
      "[CV 2/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 2/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.751) total time=  13.2s\n",
      "[CV 3/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 3/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.755) total time=  13.4s\n",
      "[CV 1/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 1/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=0.977, test=0.753) total time=  12.5s\n",
      "[CV 2/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 2/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=0.977, test=0.752) total time=  13.2s\n",
      "[CV 3/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 3/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=0.978, test=0.753) total time=  13.5s\n",
      "[CV 1/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 1/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.968, test=0.753) total time=  12.2s\n",
      "[CV 2/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 2/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.967, test=0.754) total time=  12.4s\n",
      "[CV 3/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 3/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.968, test=0.756) total time=  12.4s\n",
      "[CV 1/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 1/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.964, test=0.753) total time=  11.9s\n",
      "[CV 2/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 2/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.963, test=0.755) total time=  12.3s\n",
      "[CV 3/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 3/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.964, test=0.754) total time=  12.2s\n",
      "[CV 1/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 1/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.762) total time=  12.0s\n",
      "[CV 2/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 2/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.762) total time=  11.8s\n",
      "[CV 3/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 3/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.765) total time=  12.0s\n",
      "[CV 1/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 1/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=0.988, test=0.761) total time=  12.1s\n",
      "[CV 2/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 2/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=0.989, test=0.764) total time=  41.0s\n",
      "[CV 3/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 3/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=0.988, test=0.765) total time=  12.1s\n",
      "[CV 1/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 1/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=0.980, test=0.762) total time=  11.8s\n",
      "[CV 2/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 2/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=0.980, test=0.764) total time=  11.6s\n",
      "[CV 3/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 3/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=0.980, test=0.765) total time=  11.8s\n",
      "[CV 1/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 1/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=0.978, test=0.764) total time=  11.8s\n",
      "[CV 2/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 2/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=0.978, test=0.764) total time=  11.6s\n",
      "[CV 3/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 3/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=0.977, test=0.765) total time=  11.8s\n",
      "Best Parameters: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Test Accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'criterion':[ 'gini', 'entropy'],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf':[1,2]\n",
    "                }\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(DecisionTree, param_grid, cv=3, scoring='accuracy', return_train_score = True, verbose=10)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_DecisionTree = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_DecisionTree.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Decision Tree model to a file\n",
    "with open('Best_Models/Decision_Tree_Classifier/DecisionTree.pkl', 'wb') as file:\n",
    "    pickle.dump(best_DecisionTree, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 1/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.861) total time=  45.4s\n",
      "[CV 2/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 2/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.866) total time=  45.7s\n",
      "[CV 3/3; 1/8] START criterion=gini, min_samples_leaf=1, min_samples_split=2.....\n",
      "[CV 3/3; 1/8] END criterion=gini, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.861) total time=  45.2s\n",
      "[CV 1/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 1/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.861) total time=  45.5s\n",
      "[CV 2/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 2/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.864) total time=  45.9s\n",
      "[CV 3/3; 2/8] START criterion=gini, min_samples_leaf=1, min_samples_split=5.....\n",
      "[CV 3/3; 2/8] END criterion=gini, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.863) total time=  46.0s\n",
      "[CV 1/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 1/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.999, test=0.861) total time=  44.6s\n",
      "[CV 2/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 2/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.999, test=0.861) total time=  44.9s\n",
      "[CV 3/3; 3/8] START criterion=gini, min_samples_leaf=2, min_samples_split=2.....\n",
      "[CV 3/3; 3/8] END criterion=gini, min_samples_leaf=2, min_samples_split=2;, score=(train=0.999, test=0.859) total time=  43.9s\n",
      "[CV 1/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 1/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.998, test=0.861) total time=  44.0s\n",
      "[CV 2/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 2/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.998, test=0.863) total time=  44.5s\n",
      "[CV 3/3; 4/8] START criterion=gini, min_samples_leaf=2, min_samples_split=5.....\n",
      "[CV 3/3; 4/8] END criterion=gini, min_samples_leaf=2, min_samples_split=5;, score=(train=0.998, test=0.858) total time=  44.2s\n",
      "[CV 1/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 1/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.860) total time= 1.1min\n",
      "[CV 2/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 2/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.867) total time= 1.1min\n",
      "[CV 3/3; 5/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=2..\n",
      "[CV 3/3; 5/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=2;, score=(train=1.000, test=0.861) total time= 1.1min\n",
      "[CV 1/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 1/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.861) total time= 1.1min\n",
      "[CV 2/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 2/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.866) total time= 1.1min\n",
      "[CV 3/3; 6/8] START criterion=entropy, min_samples_leaf=1, min_samples_split=5..\n",
      "[CV 3/3; 6/8] END criterion=entropy, min_samples_leaf=1, min_samples_split=5;, score=(train=1.000, test=0.861) total time= 1.1min\n",
      "[CV 1/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 1/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=1.000, test=0.861) total time= 1.1min\n",
      "[CV 2/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 2/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=1.000, test=0.865) total time= 1.1min\n",
      "[CV 3/3; 7/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=2..\n",
      "[CV 3/3; 7/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=2;, score=(train=1.000, test=0.860) total time= 1.1min\n",
      "[CV 1/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 1/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=0.999, test=0.860) total time= 1.1min\n",
      "[CV 2/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 2/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=1.000, test=0.864) total time= 1.1min\n",
      "[CV 3/3; 8/8] START criterion=entropy, min_samples_leaf=2, min_samples_split=5..\n",
      "[CV 3/3; 8/8] END criterion=entropy, min_samples_leaf=2, min_samples_split=5;, score=(train=0.999, test=0.861) total time= 1.1min\n",
      "Best Parameters: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Test Accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'criterion':[ 'gini', 'entropy'],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf':[1,2]\n",
    "                }\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "RandomForest = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(RandomForest, param_grid, cv=3, scoring='accuracy', return_train_score = True, verbose=10)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_RandomForest = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_RandomForest.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Random Forest model to a file\n",
    "with open('Best_Models/Random_Tree_Classifier/RandomForest.pkl', 'wb') as file:\n",
    "    pickle.dump(best_RandomForest, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
